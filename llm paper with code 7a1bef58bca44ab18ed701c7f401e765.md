# llm paper with code

### 基础-Transformer Architecture：

| date | paper | code | 推荐指数(1~5递增) |
| --- | --- | --- | --- |
| Jun 2017 | https://arxiv.org/abs/1706.03762 |  | 5 |
| Jan 2019 | https://arxiv.org/abs/1901.02860 |  | 5 |
| May 2023 | https://arxiv.org/abs/2305.07185 |  | 4 |

### 基础模型：

| date | paper | code | 推荐指数 |
| --- | --- | --- | --- |
| Feb 2023 | https://arxiv.org/abs/2302.13971 |  | 5 |
| Apr 2022 | https://arxiv.org/abs/2204.02311 |  | 4 |
| Apr 2022 | https://arxiv.org/abs/2204.06745 |  | 4 |
| Jul 2023 | https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf (OpenAI) - GPT-2 |  | 5 |
| Jul 2023 | https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/ |  | 5 |
| Dec 2023 | https://arxiv.org/abs/2312.00752 |  | 5 |

### 训练/推理框架

| date | paper | code | 推荐指数 |
| --- | --- | --- | --- |
| Sep 2019 | https://arxiv.org/abs/1909.08053 |  | 5 |
| Sep 2023 | https://arxiv.org/pdf/2309.06180.pdf |  | 5 |
| May 2023 | https://arxiv.org/pdf/2303.06865.pdf |  | 5 |
| Sep 2023 | https://arxiv.org/pdf/2309.17453.pdf |  | 5 |
| Jan 2024 | https://arxiv.org/pdf/2401.08671.pdf |  | 5 |
| Dec 2023 | https://arxiv.org/pdf/2312.08361.pdf |  | 5 |

### 模型压缩/量化：

| date | paper | code | 推荐指数 |
| --- | --- | --- | --- |
| Jun 2022 | https://arxiv.org/pdf/2206.01861.pdfhttps://arxiv.org/pdf/2206.01861.pdfhttps://arxiv.org/pdf/2206.01861.pdf |  | 5 |
| Nov 2022 | https://arxiv.org/pdf/2208.07339.pdf |  | 5 |
| Mar 2023 | https://arxiv.org/pdf/2210.17323.pdf |  | 5 |
| Nov 2022 | https://arxiv.org/pdf/2211.10017.pdfhttps://arxiv.org/pdf/2211.10017.pdfhttps://arxiv.org/pdf/2211.10017.pdf |  | 5 |
| Nov 2022 | [SmoothQuant] Accurate and Efficient Post-Training Quantization for Large Language Models |  | 4 |
| Jun 2023 | https://github.com/mit-han-lab/llm-awq |  | 5 |

### 微调：

| date | paper | code | 推荐指数 |
| --- | --- | --- | --- |
| Jun 2021 | https://arxiv.org/abs/2106.09685 |  | 5 |
| May 2023 | https://arxiv.org/abs/2305.14314 |  | 5 |
| Oct 2022 | https://arxiv.org/abs/2210.07558  |  | 4 |
| Jun 2023 | https://arxiv.org/abs/2306.09782 |  | 5 |

### Agent：

| date | paper | code | 推荐指数 |
| --- | --- | --- | --- |
| 2023.2 | https://arxiv.org/abs/2302.02083 | - | 4 |
| 2023.4 | https://arxiv.org/abs/2304.05335 | - | 5 |
| 2023.5 | https://arxiv.org/abs/2305.16867 | - | 4 |
| 2023.7 | https://arxiv.org/abs/2307.00184 | - | 4 |
| 2023.4 | https://arxiv.org/abs/2304.11158 | - | 4 |
| 2023.11 | https://arxiv.org/abs/2311.05997 |  | 5 |
| 2022.10 | https://arxiv.org/abs/2210.03629 | - | 5 |
| 2023.3 | https://arxiv.org/abs/2303.11366 | https://github.com/noahshinn/reflexion | 5 |
| 2024.01 | https://arxiv.org/abs/2401.05268 |  | 5 |
| 2023.2 | https://arxiv.org/abs/2302.04761 |  | 5 |

### RAG：

| date | paper | code | 推荐指数 |
| --- | --- | --- | --- |
| Nov 2023 | https://arxiv.org/abs/2311.09210 | - | 5 |
| Feb 2024 | https://openreview.net/forum?id=hSyW5go0v8 | - | 5 |
| Nov 2023 | https://arxiv.org/abs/2311.08252 |  | 5 |
|  Jan 2024 | https://openreview.net/forum?id=22OTbutug9 | - | 4 |
| Jan 2023 | https://uploads-ssl.webflow.com/60fd4503684b466578c0d307/63c6c20dec4479564db21819_NEW_In_Context_Retrieval_Augmented_Language_Models.pdf |  | 4 |

引用：

[https://github.com/Hannibal046/Awesome-LLM](https://github.com/Hannibal046/Awesome-LLM)

[https://github.com/zjunlp/LLMAgentPapers](https://github.com/zjunlp/LLMAgentPapers)

[https://github.com/DefTruth/Awesome-LLM-Inference?tab=readme-ov-file#Continuous-In-flight-Batching](https://github.com/DefTruth/Awesome-LLM-Inference?tab=readme-ov-file#Continuous-In-flight-Batching)

[https://github.com/mlabonne/llm-course](https://github.com/mlabonne/llm-course)

[https://github.com/jxzhangjhu/Awesome-LLM-RAG](https://github.com/jxzhangjhu/Awesome-LLM-RAG)